{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adong-hood/dm-24/blob/main/module_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIVXc6MvxdTG"
      },
      "source": [
        "# Module 3: Data Exploration\n",
        "\n",
        "The following tutorial contains examples of Python code for data exploration. You should refer to the \"Data Exploration\" chapter of the \"Introduction to Data Mining\" book (available at https://www-users.cs.umn.edu/~kumar001/dmbook/index.php) to understand some of the concepts introduced in this tutorial notebook. The notebook can be downloaded from http://www.cse.msu.edu/~ptan/dmbook/tutorials/tutorial3/tutorial3.ipynb.\n",
        "\n",
        "Data exploration refers to the preliminary investigation of data in order\n",
        "to better understand its specific characteristics. There are two key motivations for data exploration:\n",
        "1. To help users select the appropriate preprocessing and data analysis technique used.\n",
        "2. To make use of humansâ€™ abilities to recognize patterns in the data.\n",
        "\n",
        "Read the step-by-step instructions below carefully. To execute the code, click on the cell and press the SHIFT-ENTER keys simultaneously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BNhEUR7xdTN"
      },
      "source": [
        "## 3.1. Summary Statistics\n",
        "\n",
        "Summary statistics are quantities, such as the mean and standard deviation, that capture various characteristics of a potentially large set of values with a single number or a small set of numbers. In this tutorial, we will use the Iris sample data, which contains information on 150 Iris flowers, 50 each from one of three Iris species: Setosa, Versicolour, and Virginica. Each flower is characterized by five attributes:\n",
        "\n",
        "- sepal length in centimeters\n",
        "\n",
        "- sepal width in centimeters\n",
        "\n",
        "- petal length in centimeters\n",
        "\n",
        "- petal width in centimeters\n",
        "\n",
        "- class (Setosa, Versicolour, Virginica)\n",
        "\n",
        "In this tutorial, you will learn how to:\n",
        "\n",
        "- Load a CSV data file into a Pandas DataFrame object.\n",
        "\n",
        "- Compute various summary statistics from the DataFrame.\n",
        "\n",
        "To execute the sample program shown here, make sure you have installed the Pandas library (see Module 2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLy6o_vDxdTO"
      },
      "source": [
        "**1.** First, you need to download the <a href=\"http://archive.ics.uci.edu/ml/datasets/Iris\">Iris dataset</a> from the UCI machine learning repository.\n",
        "\n",
        "**<font color='red'>Code:</font>** The following code uses Pandas to read the CSV file and store them in a DataFrame object named data. Next, it will display the first five rows of the data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiXdyVilxdTP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',header=None)\n",
        "data.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVwTOO_QxdTR"
      },
      "source": [
        "**2.** For each quantitative attribute, calculate its average, standard deviation, minimum, and maximum values.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Fia1wWoxdTS"
      },
      "outputs": [],
      "source": [
        "from pandas.api.types import is_numeric_dtype\n",
        "\n",
        "for col in data.columns:\n",
        "    if is_numeric_dtype(data[col]):\n",
        "        print('%s:' % (col))\n",
        "        print('\\t Mean = %.2f' % data[col].mean())\n",
        "        print('\\t Standard deviation = %.2f' % data[col].std())\n",
        "        print('\\t Minimum = %.2f' % data[col].min())\n",
        "        print('\\t Maximum = %.2f' % data[col].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69MjqGfWxdTT"
      },
      "source": [
        "**3.** For the qualitative attribute (class), count the frequency for each of its distinct values.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZlxeGe3xdTT"
      },
      "outputs": [],
      "source": [
        "data['class'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km-G9CuexdTU"
      },
      "source": [
        "**4.** It is also possible to display the summary for all the attributes simultaneously in a table using the describe() function. If an attribute is quantitative, it will display its mean, standard deviation and various quantiles (including minimum, median, and maximum) values. If an attribute is qualitative, it will display its number of unique values and the top (most frequent) values.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f_r1yyqxdTV"
      },
      "outputs": [],
      "source": [
        "data.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugs2A1SzxdTW"
      },
      "source": [
        "Note that count refers to the number of non-missing values for each attribute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcgaxNKPxdTW"
      },
      "source": [
        "**5.** For multivariate statistics, you can compute the covariance and correlation between pairs of attributes.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntbfGTAvxdTW"
      },
      "outputs": [],
      "source": [
        "print('Covariance:')\n",
        "numeric_data = data[['sepal length', 'sepal width', 'petal length', 'petal width']]\n",
        "numeric_data.cov()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5S8C9VwvxdTX"
      },
      "outputs": [],
      "source": [
        "print('Correlation:')\n",
        "numeric_data = data[['sepal length', 'sepal width', 'petal length', 'petal width']]\n",
        "numeric_data.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrxcWcZfxdTX"
      },
      "source": [
        "## 3.2. Data Visualization\n",
        "\n",
        "Data visualization is the display of information in a graphic or tabular format. Successful visualization requires that the data (information) be converted into a visual format so that the characteristics of the data and the relationships\n",
        "among data items or attributes can be analyzed or reported.\n",
        "\n",
        "In this tutorial, you will learn how to display the Iris data created in Section 3.1. To execute the sample program shown here, make sure you have installed the matplotlib library package (see Module 0 on how to install Python packages)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5Zz3Cu8xdTX"
      },
      "source": [
        "**1.** First, we will display the histogram for the sepal length attribute by discretizing it into 8 separate bins and counting the frequency for each bin.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UM9-vDLxdTX"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "data['sepal length'].hist(bins=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJPwInCcxdTY"
      },
      "source": [
        "**2.** A boxplot can also be used to show the distribution of values for each attribute.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIYyW3PaxdTY"
      },
      "outputs": [],
      "source": [
        "data.boxplot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qy4-me2xdTY"
      },
      "source": [
        "**3.** For each pair of attributes, we can use a scatter plot to visualize their joint distribution.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgOlQHpcxdTY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(3, 2, figsize=(12,12))\n",
        "index = 0\n",
        "for i in range(3):\n",
        "    for j in range(i+1,4):\n",
        "        ax1 = int(index/2)\n",
        "        ax2 = index % 2\n",
        "        axes[ax1][ax2].scatter(data[data.columns[i]], data[data.columns[j]], color='red')\n",
        "        axes[ax1][ax2].set_xlabel(data.columns[i])\n",
        "        axes[ax1][ax2].set_ylabel(data.columns[j])\n",
        "        index = index + 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create pairwise scatterplots\n",
        "scatter_matrix(data, alpha=0.8, figsize=(12, 12), diagonal='kde', color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E_cuL6onm110"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQBQRtxuxdTZ"
      },
      "source": [
        "**4.** Parallel coordinates can be used to display all the data points simultaneously. Parallel coordinates have one coordinate axis for each attribute, but the different axes are parallel to one other instead of perpendicular, as is traditional. Furthermore, an object is represented as a line instead of as a point. In the example below, the distribution of values for each class can be identified in a separate color.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdwgqRe3xdTZ"
      },
      "outputs": [],
      "source": [
        "from pandas.plotting import parallel_coordinates\n",
        "%matplotlib inline\n",
        "\n",
        "parallel_coordinates(data, 'class')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk5lyiHZxdTZ"
      },
      "source": [
        "## 3.3. Summary\n",
        "\n",
        "This tutorial presents several examples for data exploration and visualization using the Pandas and matplotlib library packages available in Python.\n",
        "\n",
        "**<font color='blue'>References:</font>**\n",
        "\n",
        "1. Documentation on Pandas. https://pandas.pydata.org/\n",
        "2. Documentation on matplotlib. https://matplotlib.org/\n",
        "3. Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More Examples"
      ],
      "metadata": {
        "id": "w7BC2DexhrfE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxXwZTt6025Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bcbc0ce-d89f-4f0a-d650-a046667b8323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFoUx6bN0svf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_QX3bHy0Pe0"
      },
      "outputs": [],
      "source": [
        "happiness_df = pd.read_csv('http://pluto.hood.edu/~dong/datasets/happiness_2017.csv')\n",
        "happiness_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT-lbqoG1I70"
      },
      "outputs": [],
      "source": [
        "print(happiness_df.shape)\n",
        "happiness_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PX1jc6g-0Zr0"
      },
      "outputs": [],
      "source": [
        "life_ladder_df = happiness_df[['Life Ladder','Generosity']]\n",
        "print(life_ladder_df['Life Ladder'].min())\n",
        "print(life_ladder_df.shape)\n",
        "life_ladder_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Bx3SgTTVrP_"
      },
      "outputs": [],
      "source": [
        "# selecting multiple columns by names.\n",
        "df_1 = happiness_df.loc[:, 'Life Ladder':'Generosity']\n",
        "df_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeJodT7_W1g5"
      },
      "outputs": [],
      "source": [
        "# slicing\n",
        "df_2 = happiness_df.iloc[10:100, 5:10]\n",
        "df_2.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juUOCw2S1k-q"
      },
      "outputs": [],
      "source": [
        "happiness_df['Region'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1U3zwVDI14t6"
      },
      "outputs": [],
      "source": [
        "western_enrope_df = happiness_df[happiness_df['Region'] == \"Western Europe\"]\n",
        "print(western_enrope_df.shape)\n",
        "western_enrope_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcFW5aXxgJ3k"
      },
      "outputs": [],
      "source": [
        "numeric_data_df = happiness_df.select_dtypes(include=['number'])\n",
        "correlation_matrix = numeric_data_df.corr()\n",
        "correlation_matrix.style.background_gradient(cmap='coolwarm')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = happiness_df.select_dtypes(include=['number']).corr()\n",
        "#print(type(correlation_matrix))\n",
        "correlation_matrix=correlation_matrix[correlation_matrix < 1].stack()\n",
        "#print(type(correlation_matrix))\n",
        "print(correlation_matrix)\n",
        "correlation_matrix_pos = correlation_matrix.idxmax()\n",
        "#print(type(correlation_matrix_pos))\n",
        "print(correlation_matrix_pos)\n",
        "max_corr_value = correlation_matrix[correlation_matrix_pos]\n",
        "print(max_corr_value)"
      ],
      "metadata": {
        "id": "Gn_dXhSKp98S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pICS-OjkzxxF"
      },
      "source": [
        "## Homework 2 ##\n",
        "\n",
        "**Please do not manually look for answers even if you can. <font color=\"red\">Your Homework 2 submission should only include content from this point on. pdf, not ipynb.</font>**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YOHMnWD-xKOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHptJL4W0HVO"
      },
      "source": [
        "### Q-1: Calculating the average, standard deviation, maximum, mininum, median of happiness scores.  \n",
        "Your solution should only show these statistics for happiness scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7roeQHV014zo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQW4rupJ1jrK"
      },
      "source": [
        "### Q-2: What is the name and happiness score of the country with the lowest confidence in their national government?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSZL1JPq2Hy9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHj7cjhA1zM6"
      },
      "source": [
        "### Q-3 How many countries are in Western Europe?\n",
        "This will be very easy wiht grouping function, but you can still do it without it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvtUPGyD2Kt7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQEeAjeb4mtR"
      },
      "source": [
        "### Q-4: Which two factors have the largest positive correlation and Which two factors have the largest negative correlation?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHklfopO4wAo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwLBkvZK2IzH"
      },
      "source": [
        "## Merging data\n",
        "Let's load the world polulation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j39tVrK2mLl"
      },
      "outputs": [],
      "source": [
        "world_pop_df = pd.read_csv('http://pluto.hood.edu/~dong/datasets//world_countries.csv').dropna(axis=1, how='all')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33_YfFlt2MK2"
      },
      "source": [
        "To extract populations from world_pop_df, we have to merge happiness_df with world_pop_df. Please note some of the country names in <code>world_counties.csv</code> and <code>happiness_2007.csv</code>do not match (See[ countries mismatch file](http://pluto.hood.edu/~dong/datasets/country_mismatch_missing.txt) for your convenience.).\n",
        "\n",
        "There are 4 kinds of merge: 'inner', 'outer', 'left', and 'right'. We practiced inner merge previously.  \n",
        "\n",
        "You may find examples from https://jakevdp.github.io/PythonDataScienceHandbook/03.07-merge-and-join.html:\n",
        "Example: US States Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYtwja-U3spD"
      },
      "source": [
        "### Q-5. Which country  has the largest population in Middle East and North Africa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjdd_z8l4CKJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTfh9Apo30xC"
      },
      "source": [
        "### Q-6. Find the average population of Latin America and Caribbean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJLLUw_K4CmH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F640aBip47p2"
      },
      "source": [
        "### Q-7. Problem Statement\n",
        "You have a dataset containing information about customers and whether they purchased a product or not. The goal is to determine the best attribute to split the data based on the Gini index.\n",
        "\n",
        "Dataset\n",
        "<pre>\n",
        "Customer ID\tAge\tIncome\tPurchased\n",
        "1\t22\tHigh\tNo\n",
        "2\t35\tMedium\tYes\n",
        "3\t45\tHigh\tYes\n",
        "4\t25\tLow\tNo\n",
        "5\t30\tHigh\tYes\n",
        "6\t40\tLow\tNo\n",
        "7\t50\tMedium\tYes\n",
        "8\t28\tMedium\tNo\n",
        "</pre>\n",
        "\n",
        "Calculate the Gini index for each attribute (Age and Income) and determine which attribute should be chosen for the first split in the decision tree.\n",
        "\n",
        "For age, split the dataset into two groups based on age: younger than 30 and 30 or older. For income, split the dataset into two groups based on income: High and Medium/Low.\n",
        "\n",
        "show your work for full credits."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#do not include the output from installation.\n",
        "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
        "!pip install pypandoc\n",
        "!pip install nbconvert"
      ],
      "metadata": {
        "id": "vOABEuBsBmiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert  '/content/drive/MyDrive/datamining/module-3.ipynb' --to pdf\n"
      ],
      "metadata": {
        "id": "clJkZ1RVBzMv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}