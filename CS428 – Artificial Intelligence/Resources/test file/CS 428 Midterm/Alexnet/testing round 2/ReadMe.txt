Added Batch Normalization Layers: to base model

Batch Normalization can stabilize learning by normalizing the output of each layer, allowing the model to train faster and achieve better accuracy.