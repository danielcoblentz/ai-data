{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNeZHvi+EBuqymlsXUNUEGu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L_G62PV97Zxb","executionInfo":{"status":"ok","timestamp":1732397987202,"user_tz":300,"elapsed":1151,"user":{"displayName":"Daniel Coblentz","userId":"11470372804666385483"}},"outputId":"fbc57471-a376-4681-c066-ddba79ebfbdc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model diagram saved as 'GestureNet_model.png'\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Flatten, Dropout, Dense\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras import backend as K\n","\n","# Define the GestureNet model\n","def build_model(width, height, depth, classes):\n","    model = Sequential()\n","    inputShape = (height, width, depth)\n","    chanDim = -1\n","\n","    # Update input shape if channels first format is used\n","    if K.image_data_format() == \"channels_first\":\n","        inputShape = (depth, height, width)\n","        chanDim = 1\n","\n","    # First convolutional layer\n","    model.add(Conv2D(16, (7, 7), padding=\"same\", input_shape=inputShape))\n","    model.add(Activation(\"relu\"))\n","    model.add(BatchNormalization(axis=chanDim))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    # Second convolutional layer\n","    model.add(Conv2D(32, (3, 3), padding=\"same\"))\n","    model.add(Activation(\"relu\"))\n","    model.add(BatchNormalization(axis=chanDim))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    # Third convolutional layer\n","    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","    model.add(Activation(\"relu\"))\n","    model.add(BatchNormalization(axis=chanDim))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    # Fully connected layers\n","    model.add(Flatten())\n","    model.add(Dense(128))\n","    model.add(Activation(\"relu\"))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.5))\n","\n","    # Output layer\n","    model.add(Dense(classes))\n","    model.add(Activation(\"softmax\"))\n","\n","    return model\n","\n","# Build the model\n","model = build_model(64, 64, 3, 10)  # Example input: 64x64 RGB images with 10 output classes\n","\n","# Visualize the model and save as PNG\n","plot_model(\n","    model,\n","    to_file=\"GestureNet_model.png\",\n","    show_shapes=True,\n","    show_layer_names=True,\n","    dpi=200\n",")\n","print(\"Model diagram saved as 'GestureNet_model.png'\")\n"]}]}