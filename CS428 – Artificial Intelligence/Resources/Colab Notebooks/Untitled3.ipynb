{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPM44y9sHCpKoetNsCwPoqP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"KfbWjj-JA_Iq","executionInfo":{"status":"error","timestamp":1728591398074,"user_tz":240,"elapsed":3817,"user":{"displayName":"Daniel Coblentz","userId":"11470372804666385483"}},"outputId":"47ce5e29-067c-4dd9-d5b0-b5be91f5f9ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: patool==1.12 in /usr/local/lib/python3.10/dist-packages (1.12)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Found 14000 images belonging to 10 classes.\n","Found 6000 images belonging to 10 classes.\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'DirectoryIterator' object has no attribute 'take'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-6901c5b20d07>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Verify shapes to debug any issues before model building\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Dataset - Image batch shape: {images.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Dataset - Label batch shape: {labels.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'take'"]}],"source":["# Import necessary libraries\n","!pip install patool==1.12\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras import layers, models\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","import patoolib\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define the directory containing the dataset\n","data_dir = '/content/extracted_images/leapGestRecog'  # Adjust the path if needed\n","\n","# Use ImageDataGenerator for real-time data augmentation\n","datagen = ImageDataGenerator(validation_split=0.3, rescale=1.0/255.0)\n","\n","# Load training and validation datasets using flow_from_directory\n","train_dataset = datagen.flow_from_directory(\n","    directory=data_dir,\n","    target_size=(224, 224),  # Resize images to 224x224 pixels (VGG16 input size)\n","    batch_size=16,  # Use batch size of 16\n","    class_mode='categorical',  # Use categorical labels (one-hot encoded)\n","    subset='training',\n","    seed=123  # Seed for reproducibility\n",")\n","\n","validation_dataset = datagen.flow_from_directory(\n","    directory=data_dir,\n","    target_size=(224, 224),  # Resize images to 224x224 pixels (VGG16 input size)\n","    batch_size=16,  # Use batch size of 16\n","    class_mode='categorical',  # Use categorical labels (one-hot encoded)\n","    subset='validation',\n","    seed=123  # Seed for reproducibility\n",")\n","\n","# Display class names to verify labels\n","class_names = list(train_dataset.class_indices.keys())\n","print(\"Class Names:\", class_names)\n","num_classes = len(class_names)\n","print(f\"Number of classes: {num_classes}\")\n","\n","# Use `next()` to get a batch of data from train_dataset\n","images, labels = next(train_dataset)\n","print(f\"Batch of images shape: {images.shape}\")\n","print(f\"Batch of labels shape: {labels.shape}\")\n","\n","# Load the pre-trained VGG16 model with custom layers\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","base_model.trainable = False  # Freeze the layers in the base model\n","\n","# Add custom layers on top of VGG16\n","model = models.Sequential([\n","    base_model,\n","    layers.Flatten(),\n","    layers.Dense(256, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(num_classes, activation='softmax')  # Output layer for the number of classes\n","])\n","\n","# Compile the model with Adam optimizer\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Print the model summary to confirm the shapes\n","model.summary()\n","\n","# Train the VGG16 model with EarlyStopping and Learning Rate Scheduler\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","# Train the model\n","history = model.fit(\n","    train_dataset,\n","    validation_data=validation_dataset,\n","    epochs=10,\n","    callbacks=[early_stopping],\n","    verbose=1\n",")\n","\n","# Evaluate the model on the validation set\n","val_loss, val_acc = model.evaluate(validation_dataset, verbose=2)\n","print(f\"Validation accuracy: {val_acc:.4f}\")\n","\n","# Plot training and validation accuracy\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy for VGG16')\n","plt.show()\n"]}]}