{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN7Uiod2bcDOJ6Ub0GeQEsn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_vxzoJjElF7A"},"outputs":[],"source":["# Import necessary libraries\n","!pip install patool==1.12\n","import tensorflow as tf\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras import layers, models\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","import patoolib\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define the directory containing the dataset\n","data_dir = '/content/extracted_images/leapGestRecog'\n","\n","\n","# # 1. Rotation Only\n","# data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(\n","#     validation_split=0.3,  # Reserve 30% of the dataset for validation\n","#     rotation_range=20,     # Rotate images by up to 20 degrees\n","#     rescale=1./255         # Scale images to [0, 1] range\n","# )\n","\n","# 2. Flipping Only\n","data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(\n","    validation_split=0.3,  # Reserve 30% of the dataset for validation\n","    horizontal_flip=True,  # Randomly flip images horizontally\n","    rescale=1./255         # Scale images to [0, 1] range\n"," )\n","\n","# 3. Scaling Only\n","# data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(\n","#     validation_split=0.3,  # Reserve 30% of the dataset for validation\n","#     zoom_range=0.2,        # Zoom in/out by up to 20%\n","#     rescale=1./255         # Scale images to [0, 1] range\n","# )\n","\n","\n","train_dataset = data_augmentation.flow_from_directory(\n","    directory=data_dir,\n","    target_size=(224, 224),  # Resize images to 224x224 pixels\n","    batch_size=32,           # Load images in batches of 32\n","    class_mode='categorical',\n","    subset='training',       # Use the 'training' subset\n","    seed=123\n",")\n","\n","\n","validation_dataset = data_augmentation.flow_from_directory(\n","    directory=data_dir,\n","    target_size=(224, 224),  # Resize images to 224x224 pixels\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='validation',\n","    seed=123\n",")\n","\n","# class names to verify labels\n","class_names = list(train_dataset.class_indices.keys())\n","num_classes = len(class_names)\n","print(f\"Number of classes: {num_classes}\")\n","\n","# Load the pre-trained VGG16 model with custom layers\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","base_model.trainable = False  # Freeze the layers in the base model\n","\n","\n","model = models.Sequential([\n","    tf.keras.layers.Input(shape=(224, 224, 3)),  # Explicit input shape layer\n","    base_model,\n","    layers.Flatten(),\n","    layers.Dense(256, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(num_classes, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Print the model summary\n","model.summary()\n","\n","# Train the VGG16 model with the selected data augmentation\n","history = model.fit(\n","    train_dataset,\n","    validation_data=validation_dataset,\n","    epochs=10  # Adjust the number of epochs based on your requirements\n",")\n","\n","# Evaluate the model on the validation set\n","val_loss, val_acc = model.evaluate(validation_dataset, verbose=2)\n","print(f\"Validation accuracy with the applied augmentation: {val_acc:.4f}\")\n","\n","# Plot training and validation accuracy\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy with Data Augmentation')\n","plt.show()\n"]}]}